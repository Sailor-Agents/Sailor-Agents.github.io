[{"summary":"\u003ca href=\"https://github.com/Sailor-Agents/Terminal-Agents\" class=\"btn external\" target=\"_blank\"\u003eGITHUB\u003c/a\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eWe propose \u003cstrong\u003eReptile\u003c/strong\u003e, a terminal agent that operates under an extended \u003cstrong\u003eREPL (Read-Execute-Print-Learn)\u003c/strong\u003e protocol, where human feedback is seamlessly integrated into the agent\u0026rsquo;s execution loop.\u003c/p\u003e\n\u003cp\u003eUnlike traditional REPL (Read-Execute-Print-Loop) environments that focus solely on code evaluation, our REPL protocol emphasizes the iterative cycle of human-agent collaboration, transforming the terminal from a passive command executor into an interactive learning environment.\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://hackmd.io/_uploads/SkGiD2BWWl.png\" alt=\"image\"  /\u003e\n\u003c/p\u003e\n\u003ch2 id=\"insights\"\u003eInsights\u003c/h2\u003e\n\u003c!-- **Topic**: Terminal is universal enough but Terminal-Agent is super challenging, which is a promising testbed to push the limits of agent research.  --\u003e\n\u003cp\u003e\u003cstrong\u003eWorkflow\u003c/strong\u003e: Build the universal action space for the LLM, reserving specialized workflows only for high-risk operations.\u003c/p\u003e","title":"Reptile: Terminal-Agent with Human-in-the-loop Learning"},{"summary":"\u003cp\u003e\u003ca href=\"https://github.com/sail-sg/tty-use\" class=\"btn external\" target=\"_blank\"\u003eGITHUB\u003c/a\u003e\n\u003ca href=\"https://x.com/mavenlin/status/1977758827366817929\" class=\"btn external\" target=\"_blank\"\u003eTWITTER\u003c/a\u003e\n\u003ca href=\"https://tinyurl.com/vrwcmpks%20\" class=\"btn external\" target=\"_blank\"\u003eNOTION-Version\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eLLM systems today are gravitating toward structured \u003cstrong\u003e“tool protocols”.\u003c/strong\u003e The most prominent of these, \u003cstrong\u003eMCP\u003c/strong\u003e, defines tools through JSON schemas that describe how models can interact with a computer. But here’s the quiet irony: models already know. They’ve seen countless examples of people running commands, inspecting logs, and fixing errors — all through a single interface that’s existed for half a century: the \u003cstrong\u003eterminal\u003c/strong\u003e.\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"the-burden-of-new-protocols\"\u003eThe burden of new protocols\u003c/h3\u003e\n\u003cp\u003eModern tool frameworks like MCP describe every action in meticulous JSON. They are explicit, structured and heavy. To use them, an endless catalog of tool descriptions need to be maintained and explained in the system prompt.\u003c/p\u003e","title":"Terminal: LLM’s Last Tool"}]